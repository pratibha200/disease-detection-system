import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

books_dt = pd.read_csv(r'C:\Users\drkks\OneDrive\Desktop\majar-2\books-data\Books.csv')
ratings_dt = pd.read_csv(r'C:\Users\drkks\OneDrive\Desktop\majar-2\books-data\Ratings.csv')
user_dt = pd.read_csv(r'C:\Users\drkks\OneDrive\Desktop\majar-2\books-data\Users.csv')

books_dt.head()


ratings_dt.head()

user_dt.head()

#%%

print(books_dt.shape)
print(ratings_dt.shape)
print(user_dt.shape)
#%%
books_dt.head()


ratings_dt.head()

user_dt.head()
#%%
books_dt.isnull().sum()
#%%
ratings_dt.isnull().sum()
#%%
user_dt.isnull().sum()
#%%
books_dt=books_dt.dropna()

books_dt
#%%
books_dt.duplicated().sum()
#%%
auth = books_dt['Book-Author'].unique
auth
#%%
size  = len
#%%
rating_books.duplicated().sum()
#%%
user_dt.duplicated().sum()
#%%
# **popularity based recommendation
# **
rating_books = ratings_dt.merge(books_dt,on='ISBN')

rating_books
#%%
num_rating_df = rating_books.groupby('Book-Title').count()['Book-Rating'].reset_index()
num_rating_df.rename(columns={'Book-Rating':'num_ratings'},inplace=True)
num_rating_df
#%%
num_rating_df = rating_books.groupby('Book-Title').count()['Book-Rating'].reset_index()
num_rating_df.rename(columns={'Book-Rating':'num_ratings'},inplace=True)
num_rating_df
#%%
avg_rating_df = rating_books.groupby('Book-Title').mean()['Book-Rating'].reset_index()
avg_rating_df.rename(columns={'Book-Rating':'avg_rating'},inplace=True)
avg_rating_df

#%%
popular_df = num_rating_df.merge(avg_rating_df,on='Book-Title')
popular_df
#%%
popular_df = popular_df[popular_df['num_ratings']>=250].sort_values('avg_rating',ascending=False).head(50)
#%%
popular_df.merge(books_dt,on="Book-Title").drop_duplicates('Book-Title')

popular_df.shape
#%%
popular_df = popular_df.merge(books_dt,on='Book-Title').drop_duplicates('Book-Title')[['Book-Title','Book-Author','Image-URL-M','num_ratings','avg_rating']]

#%%
# Collaborative Filtering Based Recommender System

x = rating_books.groupby('User-ID').count()['Book-Rating'] > 200
padhe_likhe_users = x[x].index

#%%
filtered_rating = rating_books[rating_books['User-ID'].isin(padhe_likhe_users)]

y = filtered_rating.groupby('Book-Title').count()['Book-Rating']>=50
famous_books = y[y].index

final_ratings = filtered_rating[filtered_rating['Book-Title'].isin(famous_books)]
pt = final_ratings.pivot_table(index='Book-Title',columns='User-ID',values='Book-Rating')
pt.fillna(0,inplace=True)
pt

#%%
from sklearn.metrics.pairwise import cosine_similarity

similarity_scores = cosine_similarity(pt)
similarity_scores.shape
#%%
def recommend(book_name):
    # index fetch
    index = np.where(pt.index==book_name)[0][0]
    similar_items = sorted(list(enumerate(similarity_scores[index])),key=lambda x:x[1],reverse=True)[1:5]
    
    data = []
    for i in similar_items:
        item = []
        temp_df = books_dt[books_dt['Book-Title'] == pt.index[i[0]]]
        item.extend(list(temp_df.drop_duplicates('Book-Title')['Book-Title'].values))
        item.extend(list(temp_df.drop_duplicates('Book-Title')['Book-Author'].values))
        item.extend(list(temp_df.drop_duplicates('Book-Title')['Image-URL-M'].values))
        
        data.append(item)
    
    return data

recommend('1984')
#%%
import pickle
pickle.dump(popular_df,open('popular.pkl','wb'))
books_dt.drop_duplicates('Book-Title')

pickle.dump(pt,open('pt.pkl','wb'))
pickle.dump(books_dt,open('books.pkl','wb'))
pickle.dump(similarity_scores,open('similarity_scores.pkl','wb'))
